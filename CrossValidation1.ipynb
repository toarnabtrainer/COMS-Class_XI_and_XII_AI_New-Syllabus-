{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals of model evaluation**<br>\n",
    "**1.** Find the best model that represents the data<br>\n",
    "**2.** Determine how well the model will work in the future \n",
    "\n",
    "Evaluating model performance with the data used for training is not acceptable in data mining because it can easily generate overoptimistic and over fitted models. \n",
    "\n",
    "**Methods used for model evaluation**<br>\n",
    "**1.** Hold-Out<br>\n",
    "**2.** Cross Validation<br>\n",
    "\n",
    "**Model performance evaluation can be**<br>\n",
    "**1.** Classification Evaluation<br>\n",
    "**2.** Regression Evaluation<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hold-Out** - Dataset (large) is randomly divided to three subsets:<br>\n",
    "**1.** Training set is a subset of the dataset used to build predictive models.<br>\n",
    "**2.** Validation set is a subset of the dataset used to assess the performance of model built in the training phase. It provides a test platform for fine tuning model's parameters and selecting the best-performing model. Not all modeling algorithms need a validation set.<br>\n",
    "**3.** Test set or unseen examples is a subset of the dataset to assess the likely future performance of a model. If a model fit to the training set much better than it fits the test set, overfitting is probably the cause.<br>\n",
    "\n",
    "**Cross Validation** - Divide the data into k subsets of equal size. We build models k times, each time leaving out one of the subsets from training and use it as the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./CrossValidation1.png' width = 400  height=400 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]), (1797, 64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the features matrix\n",
    "X = digits.data\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, ..., 8, 9, 8]), (1797,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the target vector\n",
    "y = digits.target\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=1, shuffle=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct k-Fold Cross-Validation\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline,    # Pipeline\n",
    "                             X,           # Feature matrix\n",
    "                             y,           # Target vector\n",
    "                             cv = kf,     # Cross-validation technique\n",
    "                             scoring = \"accuracy\",      # scores of the estimator\n",
    "                             n_jobs = -1)               # Use all CPU cores\n",
    "# Returns array of scores of the estimator for each run of the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
       "        0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067]), (10,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Mean Performance Score\n",
    "cv_results, cv_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964931719428926"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
